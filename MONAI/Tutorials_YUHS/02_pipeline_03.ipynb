{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96ohkCyqZNaM"
   },
   "source": [
    "#  MONAI Bootcamp\n",
    "## End-To-End Workflow with MONAI part 3 [train with Ignite Supervised Evaluator and Trainer]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_lPbckSZsAG"
   },
   "source": [
    "# same baseline End-to-end Training with Ignite\n",
    "We've covered a lot of material and now it's time to apply the things that we've learned in an end-to-end example. First, we're going to use the basic PyTorch paradigm for training our model. We'll then look at how to train using the Ignite workflows to make things even easier!\n",
    "\n",
    "## baseline  End-to-End Training Workflow\n",
    "To help guide you through training your first model using MONAI, this guide will will cover five key phases:\n",
    "\n",
    " 1. Setting up our Dataset and exploring the data\n",
    " 2. Preparing datasets and transforms\n",
    " 3. Define your network and create our PyTorch training loop [replace with ignite]\n",
    " 4. Evaluate your model and understand the results\n",
    " \n",
    "Let's get started by importing our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qg9upTKtVga-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import monai\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.data import decollate_batch, partition_dataset_classes\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    AddChannel,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    ToTensor,\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    EnsureType\n",
    ")\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check GPU memory with `nvidia-smi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBZIJLrJZ1IQ"
   },
   "source": [
    "## 1. Setting up our Dataset and exploring the data\n",
    "#### Setup data directory\n",
    "\n",
    "We'll create a temporary directory for all the MONAI data we're going to be using called temp directory in `~/monai-lab/temp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOX-pVqQVo01",
    "outputId": "cc1d2154-c38c-459b-92c9-4b9263447b90"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "directory = \"temp\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQQ26Fv9Z-xK"
   },
   "source": [
    "Download the MedNIST dataset\n",
    "The MedNIST dataset was gathered from several sets from [TCIA](https://wiki.cancerimagingarchive.net/display/Public/Data+Usage+Policies+and+Restrictions), [the RSNA Bone Age Challenge](http://rsnachallenges.cloudapp.net/competitions/4), and the [NIH Chest X-ray dataset](https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest).\n",
    "\n",
    "The dataset is kindly made available by [Dr. Bradley J. Erickson M.D., Ph.D.](https://www.mayo.edu/research/labs/radiology-informatics/overview) (Department of Radiology, Mayo Clinic) under the Creative Commons CC BY-SA 4.0 license. If you use the MedNIST dataset, please acknowledge the source.\n",
    "\n",
    "We're going to download this dataset below and extract it into our temporary MONAI Data Directory.\n",
    "It will take about 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_yH3E2_VvX7",
    "outputId": "04200657-6aea-4747-ad99-efe377a0dce3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "resource = \"https://www.dropbox.com/s/5wwskxctvcxiuea/MedNIST.tar.gz?dl=1\"\n",
    "md5 = \"0bc7306e7427e00ad1c5526a6677552d\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"MedNIST.tar.gz\")\n",
    "data_dir = os.path.join(root_dir, \"MedNIST\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccI6haMfaYSF"
   },
   "source": [
    "### Set deterministic training for reproducibility\n",
    "\n",
    "[`set_determinism`](https://docs.monai.io/en/latest/utils.html?highlight=set_determinism#monai.utils.misc.set_determinism) will set the random seeds in both Numpy and PyTorch to ensure reproducibility. We'll see later that we need to go a little bit further to ensure reproducibility in a jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwYpFBImV1hJ"
   },
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uKHIr0Jaj2s"
   },
   "source": [
    "#### Read the image filenames from the dataset folders\n",
    "\n",
    "When using a dataset, you want to understand the basics of the images, labels, and more. We'll start off by showing some of those basic statistics for MedNIST.\n",
    "\n",
    "We'll see that 6 different folders are representing 6 different categories: Hand, AbdomenCT, CXR, ChestCT, BreastMRI, HeadCT. We'll be using each of these categories as our label names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4T6KV7lV1ng",
    "outputId": "933bcb83-46c1-472d-b5db-c0e786b816c3"
   },
   "outputs": [],
   "source": [
    "class_names = sorted(x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x)))\n",
    "num_class = len(class_names)\n",
    "\n",
    "image_files = [\n",
    "    [\n",
    "        os.path.join(data_dir, class_names[i], x)\n",
    "        for x in os.listdir(os.path.join(data_dir, class_names[i]))\n",
    "    ]\n",
    "    for i in range(num_class)\n",
    "]\n",
    "\n",
    "num_each = [len(image_files[i]) for i in range(num_class)]\n",
    "image_files_list = []\n",
    "image_class = []\n",
    "\n",
    "for i in range(num_class):\n",
    "    image_files_list.extend(image_files[i])\n",
    "    image_class.extend([i] * num_each[i])\n",
    "    \n",
    "num_total = len(image_class)\n",
    "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
    "\n",
    "print(f\"Total image count: {num_total}\")\n",
    "print(f\"Image dimensions: {image_width} x {image_height}\")\n",
    "print(f\"Label names: {class_names}\")\n",
    "print(f\"number of Labels: {num_class}\")\n",
    "print(f\"Label counts: {num_each}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yx-WedqRWDbt"
   },
   "source": [
    "# 2. Preparing datasets and transforms\n",
    "### Prepare training, validation, and test data lists\n",
    "\n",
    "We want to split the data into 3 different sets, one for training, one for validation, and one for testing. We'll use a ratio of 80/10/10 for those sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### current manual method(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_frac = 0.1\n",
    "test_frac = 0.1\n",
    "train_x = list()\n",
    "train_y = list()\n",
    "val_x = list()\n",
    "val_y = list()\n",
    "test_x = list()\n",
    "test_y = list()\n",
    "\n",
    "for i in range(num_total):\n",
    "    rann = np.random.random()\n",
    "    if rann < val_frac:\n",
    "        val_x.append(image_files_list[i])\n",
    "        val_y.append(image_class[i])\n",
    "    elif rann < test_frac + val_frac:\n",
    "        test_x.append(image_files_list[i])\n",
    "        test_y.append(image_class[i])\n",
    "    else:\n",
    "        train_x.append(image_files_list[i])\n",
    "        train_y.append(image_class[i])\n",
    "\n",
    "print(f\"Training count: {len(train_x)}, Validation count: {len(val_x)}, Test count: {len(test_x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQKPHOjgWHoW"
   },
   "source": [
    "### Define MONAI transforms, Dataset and Dataloader to pre-process data\n",
    "\n",
    "We'll define our transform using `Compose`. In this Array of Transforms, we'll load the image, add a channel, scale its intensity, utilize a few random functions and finally create a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaRvhLd-WTmF",
    "outputId": "619dac29-2ec4-4bb3-bf52-9bf49780c17e"
   },
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        AddChannel(),\n",
    "        ScaleIntensity(),\n",
    "        RandRotate(range_x=15, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose([LoadImage(image_only=True), AddChannel(), ScaleIntensity(), ToTensor()])\n",
    "\n",
    "act = Compose([EnsureType(), Activations(softmax=True)])\n",
    "to_onehot = Compose([EnsureType(), AsDiscrete(to_onehot=num_class, n_classes=num_class)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DeElxN0WcKt"
   },
   "source": [
    "### Initialise the datasets and loaders for training, validation and test sets\n",
    "- Define a simple dataset, that we'll call `MedNISTDataset`, that  groups:\n",
    "\n",
    " - Images\n",
    " - Labels\n",
    " - The transforms that are to be run on the images and labels\n",
    "- Create three instances of this dataset:\n",
    "  - One for training\n",
    "  - One for validation\n",
    "  - One for testing\n",
    "\n",
    "We'll use a batch size of 512 and employ 10 workers to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fag4Yd2CWTum",
    "outputId": "af0aca02-0916-4909-9da7-8a14f57c1a20"
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "num_workers = 10\n",
    "\n",
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "train_ds = MedNISTDataset(train_x, train_y, train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "val_ds = MedNISTDataset(val_x, val_y, val_transforms)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Df90U_QrW0i6"
   },
   "source": [
    "3. Define your network and create our PyTorch training loop\n",
    "Define network and optimizer\n",
    "Set learning_rate for how much the model is updated per step\n",
    "The fetch a pytorch device for the GPU\n",
    "Instantiate a `densenet121` model instance and 'send' it to the GPU using device\n",
    "This is a standard MONAI implementation; it is capable of 2D and 3D operation but here we are using it in 2D mode\n",
    "We'll make use of the Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0Fxk7CNWTxg"
   },
   "outputs": [],
   "source": [
    "# Configure \n",
    "learning_rate = 1e-5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = DenseNet121(spatial_dims=2, in_channels=1, out_channels=num_class).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMhrAYGrYc6L"
   },
   "source": [
    "## change train with ignite ( SupervisedEvaluator, SupervisedTrainer)\n",
    "\n",
    "Everything that we have done so far uses MONAI with pytorch in a very vanilla fashion. The initial training / validation loop is written to show you the nuts and bolts of pytorch. Now let's explore starting the move towards Ignite and features of MONAI designed to work with it.\n",
    "\n",
    "<img src=\"https://github.com/Project-MONAI/MONAIBootcamp2021/raw/2f28b64f814a03703667c8ea18cc84f53d6795e4/day1/workflows.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialize network, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure \n",
    "learning_rate = 1e-5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = DenseNet121(spatial_dims=2, in_channels=1, out_channels=num_class).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load ignite module and initialize  buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.metrics import Accuracy\n",
    "from monai.handlers import ROCAUC, ValidationHandler\n",
    "from monai.engines import SupervisedTrainer, SupervisedEvaluator\n",
    "step = 1\n",
    "train_epochs = 4\n",
    "iter_losses = []\n",
    "batch_sizes = []\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### configure roc metric (same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "steps_per_epoch = len(train_ds) // train_loader.batch_size\n",
    "if len(train_ds) % train_loader.batch_size != 0:\n",
    "    steps_per_epoch += 1\n",
    "\n",
    "\n",
    "def roc_auc_trans(x):\n",
    "    if isinstance(x, list):\n",
    "        pred = torch.cat([i[0][None, :] for i in x])\n",
    "        label = torch.cat([i[1][None, :] for i in x])\n",
    "        return pred, label\n",
    "\n",
    "    return act(x[\"pred\"]), to_onehot(x[\"label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### configure ignite Supervised Evaluator and trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_batch(batchdata, device, non_blocking):\n",
    "    img, classes = batchdata\n",
    "    return img.to(device), classes.to(device)\n",
    "\n",
    "\n",
    "evaluator = SupervisedEvaluator(\n",
    "    device=device,\n",
    "    val_data_loader=val_loader,\n",
    "    network=net,\n",
    "    postprocessing=roc_auc_trans,\n",
    "    key_val_metric={\"rocauc\": ROCAUC(output_transform=roc_auc_trans)},\n",
    "    prepare_batch=prepare_batch,\n",
    ")\n",
    "\n",
    "trainer = SupervisedTrainer(\n",
    "    device=device,\n",
    "    max_epochs=train_epochs,\n",
    "    train_data_loader=train_loader,\n",
    "    network=net,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    train_handlers=[ValidationHandler(1, evaluator)],\n",
    "    prepare_batch=prepare_batch,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def _end_iter(engine):\n",
    "    global step\n",
    "    loss = np.average([o[\"loss\"] for o in engine.state.output])\n",
    "    batch_len = len(engine.state.batch[0])\n",
    "    epoch = engine.state.epoch\n",
    "    epoch_len = engine.state.max_epochs\n",
    "    step_total = engine.state.iteration  \n",
    "    iter_losses.append(loss)\n",
    "    batch_sizes.append(batch_len)\n",
    "\n",
    "    print(f\"epoch {epoch}/{epoch_len}, step {step}/{steps_per_epoch}, total step {step_total}/{steps_per_epoch*epoch_len}, training_loss = {loss:.4f}\")\n",
    "    step += 1\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def run_validation(engine):\n",
    "    global step\n",
    "    # the overall average loss must be weighted by batch size\n",
    "    overall_average_loss = np.average(iter_losses, weights=batch_sizes)\n",
    "    epoch_loss_values.append(overall_average_loss)\n",
    "\n",
    "    # clear the contents of iter_losses and batch_sizes for the next epoch\n",
    "    del iter_losses[:]\n",
    "    del batch_sizes[:]\n",
    "\n",
    "    # fetch and report the validation metrics\n",
    "    roc = evaluator.state.metrics[\"rocauc\"]\n",
    "    metric_values.append(roc)\n",
    "    print(f\"evaluation for epoch {engine.state.epoch},  rocauc = {roc:.4f}\")\n",
    "    step = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss and metric\n",
    "Once we're done training we want to visualize our Loss and Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val AUC\")\n",
    "x = [(i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your model and understand the results\n",
    "### Evaluate the model on the test dataset\n",
    "\n",
    "After training and validation, we now have the best model as determined by the validation dataset. But now we need to evaluate the model on the test dataset to check whether the final model is robust and not over-fitting. We'll use these predictions to generate a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "y_true = list()\n",
    "y_pred = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data[0].to(device),\n",
    "            test_data[1].to(device),\n",
    "        )\n",
    "        pred = net(test_images).argmax(dim=1)\n",
    "        \n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some light analytics - classification report\n",
    "\n",
    "We'll utilize scikit-learn's classification report to get the precision, recall, and f1-score for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some light analytics - confusion matrix\n",
    "\n",
    "Let's also create a confusion matrix to get a better understanding of the failure cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cmat = confusion_matrix(y_true, y_pred)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion_matrix(y_true, y_pred), cmap=\"terrain\", interpolation='nearest')\n",
    "fig.colorbar(cax)\n",
    "\n",
    "ax.set_xticklabels(['']+class_names, rotation=270)\n",
    "ax.set_yticklabels(['']+class_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caution !!!\n",
    "### please shutdown all kernels with [Kernel] menu >  [Shutdown All Kernel]  before launch next notebook\n",
    "\n",
    "## Navigation\n",
    "- [01_getting started](./01_getting.ipynb)\n",
    "\n",
    "- [02_pipeline_01](./02_pipeline_01.ipynb)\n",
    "- [02_pipeline_02 ](./02_pipeline_02.ipynb)\n",
    "- [02_pipeline_03](./02_pipeline_03.ipynb)\n",
    "- [02_pipeline_04 Next ](./02_pipeline_04.ipynb)\n",
    "\n",
    "- [03_brain_gan ](./03_brain_gan_01.ipynb)\n",
    "\n",
    "- [04_spleen_segment](./04_spleen_segment.ipynb) \n",
    "\n",
    "- [05_challenge_cardiac baseline](./05_challenge_cardiac_baseline.ipynb) \n",
    "\n",
    "- [05_challenge_cardiac workspace](./05_challenge_cardiac_workspace.ipynb) \n",
    "\n",
    "<img src=\"https://github.com/Project-MONAI/MONAIBootcamp2021/raw/2f28b64f814a03703667c8ea18cc84f53d6795e4/day1/monai.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Monai_bootcamp_01_03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
